# yaml-language-server: $schema=https://raw.githubusercontent.com/helm-unittest/helm-unittest/main/schema/helm-testsuite.json
suite: Regression Test Kubernetes Application Alerts
templates:
  - alerts/alerts-kubernetes-application.yaml
release:
  name: ut
tests:
  - it: should render kubernetes application alerts when prometheus and kubernetesApplication are enabled
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - isKind:
          of: PrometheusRule
      - equal:
          path: metadata.name
          value: ut-kubernetes-application-alerts
      - equal:
          path: metadata.labels.alertGroup
          value: kubernetes-application
      - equal:
          path: spec.groups[0].name
          value: ut-kubernetes-application
      - isNotEmpty:
          path: spec.groups[0].rules

  - it: should not render when prometheus is disabled
    set:
      prometheus.enabled: false
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - hasDocuments:
          count: 0

  - it: should not render when kubernetesApplication alerts are disabled
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: false
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - hasDocuments:
          count: 0

  - it: should not render when monitoring.coreos.com/v1 API is not available
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
    capabilities:
      apiVersions: []
    asserts:
      - hasDocuments:
          count: 0

  - it: should render with custom for duration
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.for: "10m"
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - isKind:
          of: PrometheusRule
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubePodCrashLooping
            expr: |
              max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", namespace="NAMESPACE", pod=~"ut-.*"}[5m]) >= 1
            for: 5m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff")'
              runbook_url: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy
              summary: Pod {{ $labels.pod }} is crash looping
          count: 1

  - it: should disable specific alerts when configured
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.disabled:
        KubePodCrashLooping: true
        KubePodNotReady: true
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - isKind:
          of: PrometheusRule
      - notContains:
          path: spec.groups[0].rules
          content:
            alert: KubePodCrashLooping
      - notContains:
          path: spec.groups[0].rules
          content:
            alert: KubePodNotReady

  - it: should apply custom rules for severity and timing
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.customRules:
        KubePodCrashLooping:
          for: "10m"
          severity: "critical"
        KubeDeploymentReplicasMismatch:
          for: "20m"
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - isKind:
          of: PrometheusRule
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubePodCrashLooping
            expr: |
              max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", namespace="NAMESPACE", pod=~"ut-.*"}[5m]) >= 1
            for: "10m"
            labels:
              severity: "warning"
              alertGroup: kubernetes-application
            annotations:
              description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff")'
              runbook_url: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy
              summary: Pod {{ $labels.pod }} is crash looping

  - it: should include additional labels when configured
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
      prometheus.defaultAlerts.additionalLabels:
        environment: production
        team: backend
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - isKind:
          of: PrometheusRule
      - equal:
          path: metadata.labels.environment
          value: production
      - equal:
          path: metadata.labels.team
          value: backend

  - it: should contain expected kubernetes application alerts
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - isKind:
          of: PrometheusRule
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubePodCrashLooping
            expr: |
              max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", namespace="NAMESPACE", pod=~"ut-.*"}[5m]) >= 1
            for: 5m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff")'
              runbook_url: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy
              summary: Pod {{ $labels.pod }} is crash looping
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubePodNotReady
            expr: |
              sum by (namespace, pod) (
                max by (namespace, pod) (
                  kube_pod_status_phase{namespace="NAMESPACE", pod=~"ut-.*", phase=~"Pending|Unknown|Failed"}
                ) * on (namespace, pod) group_left(owner_kind) topk by (namespace, pod) (
                  1, max by (namespace, pod, owner_kind) (kube_pod_owner{namespace="NAMESPACE", pod=~"ut-.*", owner_kind!="Job"})
                )
              ) > 0
            for: 15m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes
              runbook_url: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions
              summary: Pod {{ $labels.pod }} is not ready
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubeDeploymentReplicasMismatch
            expr: |
              (
                kube_deployment_spec_replicas{namespace="NAMESPACE", deployment="ut"}
                  >
                kube_deployment_status_replicas_available{namespace="NAMESPACE", deployment="ut"}
              ) and (
                changes(kube_deployment_status_replicas_updated{namespace="NAMESPACE", deployment="ut"}[10m])
                  ==
                0
              )
            for: 15m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes
              runbook_url: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
              summary: Deployment ut has mismatched replicas
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubeDeploymentRolloutStuck
            expr: |
              kube_deployment_status_condition{condition="Progressing", status="false", namespace="NAMESPACE", deployment="ut"}
              != 0
            for: 15m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: Rollout of deployment {{ $labels.namespace }}/{{ $labels.deployment }} is not progressing for longer than 15 minutes
              runbook_url: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
              summary: Deployment ut rollout is stuck

  - it: should have correct expression format for crash looping alert
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - isKind:
          of: PrometheusRule
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubePodCrashLooping
            expr: |
              max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", namespace="NAMESPACE", pod=~"ut-.*"}[5m]) >= 1
            for: 5m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff")'
              runbook_url: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy
              summary: Pod {{ $labels.pod }} is crash looping

  - it: should contain job and statefulset related alerts
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - isKind:
          of: PrometheusRule
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubeJobFailed
            expr: |
              kube_job_failed{namespace="NAMESPACE", job_name=~"ut-.*"} > 0
            for: 0m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete. Removing failed job after investigation should clear this alert
              runbook_url: https://kubernetes.io/docs/concepts/workloads/controllers/job/
              summary: Job {{ $labels.job_name }} failed
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubeJobNotCompleted
            expr: |
              time() - max by (namespace, job_name) (kube_job_status_start_time{namespace="NAMESPACE", job_name=~"ut-.*"}
                and
              kube_job_status_active{namespace="NAMESPACE", job_name=~"ut-.*"} > 0) > 43200
            for: 0m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than {{ "43200" | humanizeDuration }} to complete
              runbook_url: https://kubernetes.io/docs/concepts/workloads/controllers/job/
              summary: Job {{ $labels.job_name }} did not complete in time
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubeStatefulSetReplicasMismatch
            expr: |
              (
                kube_statefulset_status_replicas_ready{namespace="NAMESPACE", statefulset=~"ut-.*"}
                  !=
                kube_statefulset_replicas{namespace="NAMESPACE", statefulset=~"ut-.*"}
              ) and (
                changes(kube_statefulset_status_replicas_updated{namespace="NAMESPACE", statefulset=~"ut-.*"}[10m])
                  ==
                0
              )
            for: 15m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes
              runbook_url: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/
              summary: StatefulSet {{ $labels.statefulset }} has mismatched replicas

  - it: should contain HPA and PVC related alerts
    set:
      prometheus.enabled: true
      prometheus.defaultAlerts.kubernetesApplication.enabled: true
    capabilities:
      apiVersions:
        - monitoring.coreos.com/v1
    asserts:
      - isKind:
          of: PrometheusRule
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubeHpaReplicasMismatch
            expr: |
              (kube_horizontalpodautoscaler_status_desired_replicas{namespace="NAMESPACE", horizontalpodautoscaler="ut"}
                !=
              kube_horizontalpodautoscaler_status_current_replicas{namespace="NAMESPACE", horizontalpodautoscaler="ut"})
                and
              (kube_horizontalpodautoscaler_status_current_replicas{namespace="NAMESPACE", horizontalpodautoscaler="ut"}
                >
              kube_horizontalpodautoscaler_spec_min_replicas{namespace="NAMESPACE", horizontalpodautoscaler="ut"})
                and
              (kube_horizontalpodautoscaler_status_current_replicas{namespace="NAMESPACE", horizontalpodautoscaler="ut"}
                <
              kube_horizontalpodautoscaler_spec_max_replicas{namespace="NAMESPACE", horizontalpodautoscaler="ut"})
                and
              changes(kube_horizontalpodautoscaler_status_current_replicas{namespace="NAMESPACE", horizontalpodautoscaler="ut"}[15m]) == 0
            for: 15m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} has not matched the desired number of replicas for longer than 15 minutes
              runbook_url: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
              summary: HPA ut has mismatched replicas
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubeHpaMaxedOut
            expr: |
              kube_horizontalpodautoscaler_status_current_replicas{namespace="NAMESPACE", horizontalpodautoscaler="ut"}
                ==
              kube_horizontalpodautoscaler_spec_max_replicas{namespace="NAMESPACE", horizontalpodautoscaler="ut"}
            for: 15m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} has been running at max replicas for longer than 15 minutes
              runbook_url: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
              summary: HPA ut is running at max replicas
      - contains:
          path: spec.groups[0].rules
          content:
            alert: KubePersistentVolumeClaimPending
            expr: |
              kube_persistentvolumeclaim_status_phase{namespace="NAMESPACE", persistentvolumeclaim=~"ut-.*", phase="Pending"} == 1
            for: 10m
            labels:
              alertGroup: kubernetes-application
              severity: warning
            annotations:
              description: PersistentVolumeClaim {{ $labels.persistentvolumeclaim }} has been pending for more than 10 minutes
              runbook_url: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
              summary: PVC {{ $labels.persistentvolumeclaim }} is pending
